
\documentclass[a4paper]{ctexart}

\usepackage{geometry}
\geometry{left=2.0cm,right=2.0cm,top=2.5cm,bottom=2.5cm}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage[colorlinks,linkcolor=red]{hyperref}
\usepackage{xltxtra}
% \usepackage{clrscode} % 伪代码
\usepackage{listings} % 代码输出
\usepackage{algpseudocode}
% \usepackage{algorithmicx} % 写算法

\DeclareMathOperator{\sgn}{sgn}
\begin{document}

\title{非线性规划与R语言}

\author{黄湘云}
\date{\today}
\maketitle

\tableofcontents
\newpage

<<r set,include=FALSE>>=
library(knitr)
# knit_theme$set("print")
knit_theme$set("fruit")
options(prompt=">")
opts_chunk$set(size="normalsize",prompt=FALSE,tidy=TRUE,eval=FALSE,message=FALSE,warning=FALSE)
@

\section{引言}

在R帮助系统，相关程序手册和JSS论文的基础上，我踩了几个R包里的坑，分享一些使用经验，对相关的R包做了归类整理，供读者学习参考！文章以求解一个隐函数的极值为例，介绍非线性方程组的解法，这里只是冰山一角，相关R包的手册有求解更加复杂的非线性方程组案例，更多的内容请读者去探索了！

\section{非线性方程组解法}
下面考虑如何数值求解含$n$个未知变量、$n$个方程的非线性方程组
\[
F(\boldsymbol{x})=
\begin{cases}
    f_{1} (x_1,x_2,...,x_n) =  0 \\
    f_{2} (x_1,x_2,...,x_n) =  0 \\
    \hdotsfor{1}\\
    f_{n} (x_1,x_2,...,x_n) =  0
\end{cases}
\]
其中$n$大于1的正整数，每个$f_{i}(x_1,x_2,...,x_n)(i=1,2,\cdots,n)$为
$\mathbb{R}^{n}\to \mathbb{R}$的$n$元实值函数，且至少一个是非线性函数。


\subsection{两个几乎错误的解法}

这两个解法来自文献\cite{张平文2007}，只在极其特殊的情况下才能使用，而合适的例子只有充分发挥数学家的想象力去造了！没有任何实用价值，在很多文献里也看不到此等解法，因此说这是几乎错误的解法！可见看书，也不要被书给骗了！

\subsubsection{古典迭代解法}

非线性Jacobi迭代、Gauss-Seidel迭代和SOR迭代都是从线性方程组迭代解法推广而来的。
它们之间很类似，下面以非线性Jacobi迭代为例，伪代码如下：

\begin{algorithmic}[1]
\For {$k \gets 0,1,2,...$}
\For {$i \gets 1,2,...,n$}
\State    用非线性方程的求解器解
\State    $f_i(x_{1}^{(k)},...,x_{i-1}^{(k)},u,x_{i+1}^{(k)},...,x_{n}^{(k)})$ 解得$u$
\State    $x_{i}^{(k+1)} \gets u$
\EndFor
\State  如果迭代停止条件满足，则终止循环并输出$x^{(k+1)}$
\EndFor
\end{algorithmic}

用非线性Jacobi迭代法求解方程组
\begin{equation*}
\left\{ \begin{aligned}
   (x_1+3)(x_{2}^{3}-7)+18 &= 0\\
   \sin(x_2 e^{x_1}-1) &= 0
 \end{aligned} \right.
\end{equation*}
取初值$x_0=(-0.5,1.4)'$，已知精确解$x^{\star}=(0,1)'$
<<>>=
f1 <-function(x2){
  temf1<-function(x){
    (x+3)*(x2^3-7)+18
  }
  return(temf1)
}
f2 <-function(x1){
  temf2<-function(x){
    sin(x*exp(x1)-1)
  }
  return(temf2)
}
Jacobi_iter <- function(x0=c(-0.5,1.4),maxiter=100,eps=1e-10){
    N=maxiter
    x2 <- x1 <-rep(0,N)
    x1[1] = x0[1]
    x2[1] = x0[2]
    for (i in seq(N)) {
      x1[i+1] <- uniroot(f1(x2[i]),interval = c(-1,1))$root
      x2[i+1] <- uniroot(f2(x1[i]),interval = c(0,2))$root
      err <- sqrt((x1[i+1]-x1[i])^2+(x2[i+1]-x2[i])^2)
      if(err<=eps) 
        return( list(vec=cbind(x1,x2)[1:(i+1),],eqs.root=c(x1[i+1],x2[i+1]),n.iter=i+1) )
  }
}
solution <- Jacobi_iter(x0=c(-0.5,1.4),maxiter = 10,eps = 1e-5)
@
这个方法看起来可行，实际却难以操作！因为不能确定两组点列是否收敛，迭代过程中$x_1$和$x_2$的有根区间和初始值$x_0$。

\subsubsection{不动点迭代}
不动点迭代是从非线性方程求根推广而来的解法。试用此法求解下列非线性方程组
\begin{equation*}
\left\{ \begin{aligned}
  x_1 &= -\frac{\cos x_1}{81} +\frac{x_{2}^{2}}{9}+\frac{\sin x_3}{3} \\
  x_2 &=  \frac{\sin x_1}{3} +\frac{\cos x_3}{3}  \\
  x_3 &=  -\frac{\cos x_1}{9} +\frac{x_2}{3} +\frac{\sin x_3}{6}
 \end{aligned} \right.
\end{equation*}
精确解为$(0,\frac{1}{3},0)$ 
<<eval=TRUE,results='hide'>>=
fixed_iter <- function(x0=rep(0,3),maxiter=100,eps=1e-10){
  N=maxiter
  x2<- x3<-x1 <-rep(0,N)
  x1[1] =x0[1]
  x2[1] =x0[2]
  x3[1] =x0[3]
  for (i in seq(N)) {
    x1[i+1] <- -cos(x1[i])/81 + x2[i]^2/9 + sin(x3[i])/3
    x2[i+1] <- sin(x1[i])/3 + cos(x3[i])/3
    x3[i+1] <- -cos(x1[i])/9 + x2[i]/3 + sin(x3[i])/6
    err <-sqrt((x1[i+1]-x1[i])^2+(x2[i+1]-x2[i])^2+(x3[i+1]-x3[i])^2)
    if(err<=eps) return(list(vec=cbind(x1,x2,x3)[1:(i+1),],eqs.root=c(x1[i+1],x2[i+1],x3[i+1]),n.iter=i+1) )
  }
}
(solution <- fixed_iter(x0=rep(1,3),maxiter = 50,eps = 1e-5))
@
方程组的数值解为(\Sexpr{solution$eqs.root})，与精确解已经相差无几！
这是很凑巧的情况，实际上确定不动点迭代格式是很难的一件事（要保证迭代点列收敛）。

\subsection{Newton和拟Newton迭代}

Newton迭代(又称Newton-Raphson迭代)是从非线性方程求根的Newton迭代推广过来的！\\
即
$$x_{k+1}=x_{k}-\frac{f(x_{k})}{f'(x_{k})},i=0,1,\cdots$$
推广至
$$\boldsymbol{x}^{i+1}=\boldsymbol{x}^{i}-\boldsymbol{A}_{i}^{-1}\boldsymbol{F}(x^{i}),i=0,1,\cdots$$
其中
\[
\boldsymbol{A}_{i} = \boldsymbol{F'}(\boldsymbol{x}^{i}) = \left(
\begin{array}{cccc}
\frac{\partial f_1}{\partial  x_{1}^{i}} & \frac{\partial f_1}{\partial x_{2}^{i}} & \ldots & \frac{\partial f_1}{\partial x_{n}^{i}}\\
\frac{\partial f_2}{\partial  x_{1}^{i}} & \frac{\partial f_2}{\partial x_{2}^{i}} & \ldots & \frac{\partial f_2}{\partial x_{n}^{i}}\\
\vdots & \vdots &  & \vdots \\
\frac{\partial f_n}{\partial  x_{1}^{i}} & \frac{\partial f_n}{\partial x_{2}^{i}} & \ldots & \frac{\partial f_n}{\partial x_{n}^{i}}
\end{array} \right) \in \mathbb{R}^{n \times n}
\]
牛顿迭代具有二阶局部收敛性，因此是否收敛与初值的选取有关，在初值接近方程组的解时，一般保证收敛。

当方程组规模比较大时，每次重新计算$\boldsymbol{A}_{i}$是很费劲的一件事！
拟Newton迭代计算新的$\boldsymbol{A}_{i+1}$，只需要满足如下方程即可
$$\boldsymbol{A}_{i+1}(\boldsymbol{x}^{i+1}-\boldsymbol{x}^{i})=\boldsymbol{F}(\boldsymbol{x}^{i+1})-\boldsymbol{F}(\boldsymbol{x}^{i})$$
但当$n>1$时，$\boldsymbol{A}_{i+1}$并不能由上述方程唯一确定，因此通常做法是
$$\boldsymbol{A}_{i+1}=\boldsymbol{A}_{i}+\Delta \boldsymbol{A}_{i},\mathrm{rank}(\Delta \boldsymbol{A}_{i}) \geq 1$$
当$\mathrm{rank}(\Delta \boldsymbol{A}_{i}) = 1$时，称为秩1拟Newton法，其完整的迭代格式如下：
\begin{equation*}
\left\{ \begin{aligned}
  \boldsymbol{x}^{i+1} &= \boldsymbol{x}^{i}-\boldsymbol{A}_{i}^{-1}\boldsymbol{F}(x^{i}) \\
  \boldsymbol{A}_{i+1} &= \boldsymbol{A}_{i}+[\boldsymbol{y}^{i}-\boldsymbol{A}_{i}\boldsymbol{r}^{i}]\frac{(\boldsymbol{r}^{i})^{T}}{(\boldsymbol{r}^{i})^{T}\boldsymbol{r}^{i}} \\
  &= \boldsymbol{A}_{i} +\boldsymbol{F}(\boldsymbol{x}^{i+1})\frac{(\boldsymbol{r}^{i})^{T}}{(\boldsymbol{r}^{i})^{T}\boldsymbol{r}^{i}} 
 \end{aligned} \right.
\end{equation*}
其中$\boldsymbol{r}^{i}=\boldsymbol{x}^{i+1}-\boldsymbol{x}^{i},\boldsymbol{y}^{i}=\boldsymbol{F}(\boldsymbol{x}^{i+1})-\boldsymbol{F}(\boldsymbol{x}^{i})$，推导细节可以参考文献\cite{吴勃英2003}。

Newton法和拟Newton法是求解非线性方程组最著名的算法，但是，Newton法每次迭代都要计算雅可比矩阵$A_{i}$，拟Newton法每次间接求解雅可比矩阵，这在方程组规模比较大的时候，实现迭代过程需要的存储空间和计算量是非常可观的，不利于推广！
\subsection{Barzilai-Borwein算法}

基于Barzilai-Borwein算法\cite{BarBor88}的高效算法 SANE\cite{LacRay03} 和DF-SANE\cite{LacMarRay06}(这里DF表示Derivative-Free)弥补了经典的Newton迭代算法缺陷！这些算法统称为谱方法(Spectral Methods)，主要思想是构造迭代格式：
$$\boldsymbol{x}^{k+1}=\boldsymbol{x}^{k}+\alpha_{k}\boldsymbol{d}^{k},k=0,1,2,\cdots$$
其中$\alpha_{k}$是步长，$d_{k}$是搜索方向，定义如下：
\[
\boldsymbol{d}^{k} =
\begin{cases}
-F(\boldsymbol{x}^{k}) & \text{for DF-SANE},\\
\pm F(\boldsymbol{x}^{k}) & \text{for SANE}.
\end{cases}
\]
对于SANE算法，$F(\boldsymbol{x}^{k})$的符号与评价函数(merit function)$||F(\boldsymbol{x}^{k})||$的下降方向一致。
步长$\alpha_{k}$定义如下：
\[
\alpha_{k+1} =
\begin{cases}
\frac{(\boldsymbol{r}^{k})^{T}\boldsymbol{r}^{k}}{(\boldsymbol{r}^{k})^{T}\boldsymbol{y}^{k}},k=0,1,\cdots\\
\frac{(\boldsymbol{r}^{k})^{T}\boldsymbol{y}^{k}}{(\boldsymbol{y}^{k})^{T}\boldsymbol{y}^{k}},k=0,1,\cdots
\end{cases}
\]

第一种步长来自文献\cite{LacRay03}和\cite{LacMarRay06}，相应的算法记为sane-1和dfsane-1，BBsolve函数的参数对应method=1；
第二种步长来自文献\cite{BarBor88}，相应的算法记为sane-2和dfsane-2，BBsolve函数的参数对应method=2，这是默认设置；
另外第三种步长来自文献\cite{VarRol08}，定义如下
\[
\alpha_{k} =
\begin{cases}
\alpha_{0}=\min (1,\frac{1}{||F(\boldsymbol{x}_{0})||}),\\
\sgn((\boldsymbol{r}^{k-1})^{T}\boldsymbol{y}^{k-1})\frac{||(\boldsymbol{r}^{k-1})^{T}||}{||\boldsymbol{y}^{k-1}||}.
\end{cases}
\]
以上方法的数值实验比较详见文献\cite{BB}，这里强调的是使用策略，如果默认设置下，BBsolve求解失败，请切换参数method。


\section{隐函数极值与非线性方程组}

设隐函数$$z=f(x,y,z)$$
构造函数$$F=F(x,y,z)=z-f(x,y,z)$$
然后计算偏导数$$\frac{\partial z }{\partial x}= - \frac{F_{x}}{F_{z}}=0$$
和$$\frac{\partial z }{\partial y}= - \frac{F_{y}}{F_{z}}=0$$
然后联立方程求解，即得极值。因此，可以说这个问题可以看作求解方程(组)。

求下列隐函数$z$的极小值\footnote{题目来源于\url{http://www.7d-soft.com/}}
$$z=\sin [(zx-0.5)^2+2xy^2-\frac{z}{10} ]
e^ {-[ (x-0.5-e^{-y+z} )^2+y^2-\frac{z}{5}+3 ] }$$
其中，$x\in [-1,7],y\in [-2,2]$

可以求解非线性方程(组)的R包有rootSolve\cite{R-rootSolve}，BB\cite{R-BB}，nleqslv\cite{R-nleqslv}等包

就这个方程组来说，首先要求出另外两个方程：
<<eval=TRUE>>=
library(Deriv)
expr <- expression(z - sin((z * x - 0.5)^2 + 2 * x * y^2 - z/10) * exp(-((x -
                    0.5 - exp(-y + z))^2 + y^2 - z/5 + 3)))
DFun <- sapply(all.vars(expr)[-1], function(v) { 
  Simplify(D(expr, v))  # 表达式求偏导
})
# all.vars(expr)[-1]  # 适用于方程组有多个未知变量 
@
为了避免复制粘贴，利用eval函数，让表达式转为函数，得到如下方程组：
<<eval=TRUE>>=
equations <- function(m) {
  x = m[1]
  y = m[2]
  z = m[3]
  f1 <- eval(DFun$x)
  f2 <- eval(DFun$y)
  f3 <- eval(expr)
  c(f1, f2, f3)
}
@

\subsection{rootSolve包}

rootSolve包实现了Newton-Raphson算法，该算法迭代求解方程组，求解结果受初始猜测值影响，且不具有全局搜索能力，因此不能保证一定找着方程组的解。此外，非线性方程组一般有多组解，Newton-Raphson算法从不同初始值迭代，可能收敛到不同的解。

<<eval=TRUE,message=FALSE>>=
library(rootSolve)
library(numDeriv)
multiroot(f = equations, start = c(0, 0, 0))$root
multiroot(f = equations, start = c(3, -1, -0.02))$root
@
从求解的结果看，幸运的是，三个初始猜测都找到了方程的解，但是第一组解不在约束区域内（舍去），第二组是可行解，我们有理由相信还有很多组解，在所有的解中要确定最小的$Z$，如果一直猜测下去将是没完没了的。

\subsection{BB包}

BB包实现了基于Barzilai-Borwein方法的SANE和DF-SANE算法，算法内容参见文献\cite{BB}。
BB包能求解非线性方程组(BBsolve函数)，搜索目标函数的局部极值(BBoptim函数)，
极小的内存要求，适合求解成千上万个变量的高维问题。
<<eval=TRUE>>=
library(BB)
p1 <- c(3, -1, -0.02)
# trace 是否显示迭代过程，tol是迭代的终止条件
BBsolve(par = p1, fn = equations,control = list(trace=FALSE,tol=1e-15))$par
@

\subsection{nleqslv包}
nleqslv包基于Broyden 秩1 修正和Newton 算法，采用全局线搜索
(cubic，quadratic or geometric) 和信赖域方法
(double dogleg，Powell single dogleg or Levenberg-Marquardt type) 
求解非线性方程组，雅可比矩阵可以奇异(病态)。

searchZeros函数较之前两个包求解方程组，可以同时从一组随机设定的初始值迭代求解。
<<eval=TRUE>>=
library(nleqslv)
N <- 10 
set.seed(1234)
xstart <- cbind(runif(N,-1,7),runif(N,-2,2),runif(N,-1,1)) # N initial guesses
ans <- searchZeros(xstart, equations, method = "Broyden", global = "dbldog")
ans$x
@

\subsection{定初始值}

综合以上方法，有一个共同特点就是给出初值，一个好的初值，才有比较不错的结果。
因此下面就是如何去寻找一个好的初值。一个简单的办法就是将$x$和$y$构成的约束区域进行网格划分，
格点$(x_i,y_i)$代入原隐函数，然后求解一个非线性方程，这样问题就简化下来了！既然是确定初值，网格不必太细，
另外，如果维数比较高，可以在网格划分后，再随机选取一定量的格点，以避免陷入过量的计算。
<<eval=FALSE>>=
x <- seq(-1,7,length.out = 80)
y <- seq(-2,2,length.out = 40)
myfun <- function(m){
  x=m[1]
  y=m[2]
  temFun <- function(z){
    z-sin((z*x-0.5)^2+2*x*y^2-z/10)*exp(-((x-0.5-exp(-y+z))^2+y^2-z/5+3))
  }
  return(temFun)
}
xy_mat <- apply(as.matrix(expand.grid(x, y)), 1, function(x) uniroot( myfun(x),c(-10,10))$root ) 
@

计算网格中每个格点对应的$z$值后，就可以画出三维图像和等高线图。
函数图像和代码如下:
\begin{figure}[htb]
  \centering
    \includegraphics[width=.8\textwidth]{figure/Implicit_Function.pdf}
  \caption{隐函数图像}
\end{figure} 
<<echo=TRUE,eval=FALSE>>=
library(plot3D)
op<-par(mfrow=c(1,2),omi=c(0,0,0.5,0),mar=c(4,4,1,1))
z <- matrix(xy_mat, 80, 40)
persp3D(x, y, z, colvar = z, colkey = FALSE,bty="b2",
        lighting = F,theta = 30, phi = 20, ltheta = 90, 
        lphi=180,r=50,d=0.1,nticks=5,ticktype = "detailed")
xlabs<-seq(-1,7,by=1)
ylabs<-seq(-2,2,by=1)
plot(c(-1,7),c(-2,2),type = "n",axes = FALSE,
     xlab = "x",ylab = "y")
axis(1,labels=xlabs,at=xlabs,las=1)  # x-axis
axis(2,labels=ylabs,at=ylabs,las=1)  # y-axis
image(x,y,matrix(xy_mat, 80, 40),col = terrain.colors(10),add = TRUE)
contour(x, y, matrix(xy_mat, 80, 40),add = TRUE)
box()
par(op)
@
根据函数图象，不难确定合适的初始值$(3, -1, -0.02)$，至此，隐函数极值问题的方程组解法就讲到这里！


\section{隐函数极值与非线性规划}

隐函数极值问题还可以转化为非线性规划问题(NLPs)，然后用非线性优化方法求解，即求解规划问题\footnote{与商业软件1stOpt计算结果一致}

\begin{equation*}
\begin{array}{l}
 \min \ z  \\
 s.t.\left\{ \begin{array}{l}
  z=\sin [(zx-0.5)^2+2xy^2-\frac{z}{10} ]
e^ {-[ (x-0.5-e^{-y+z} )^2+y^2-\frac{z}{5}+3 ] } \\
  - 1 \leqslant x \leqslant 7 \\
  - 2 \leqslant y \leqslant 2 
 \end{array} \right.
 \end{array}
\end{equation*}

<<NLPs,eval=TRUE>>=
# 目标函数
fn1 <- function(x){
  x[3]  # z 
}
# 等式约束
eqn1 <- function(x){
  # x是向量，分量分别对应x,y,z
  x[3]-sin((x[3] * x[1] - 0.5)^2 + 2 * x[1] * x[2]^2 - x[3]/10) * exp(-((x[1] -0.5 - exp(-x[2] + x[3]))^2 + x[2]^2 - x[3]/5 + 3))
}
@

\subsection{alabama包}

<<alabama,eval=TRUE>>=
library(alabama)
x0 <- c(2,-1,0)
## 不等式约束
hin <- function(x){
  h <- rep(NA,4)
  h[1] <- x[1]+1
  h[2] <- 7-x[1]
  h[3] <- x[2]+2
  h[4] <- 2-x[2]
  h
}
constrOptim.nl(par = x0,fn=fn1,heq = eqn1,hin = hin,control.outer = list(trace=FALSE))$par
@
一个简单的箱式约束(box constraints)都写得这么复杂，这是alabama包的缺点。


\subsection{Rdonlp2包}

<<Rdonlp2,eval=TRUE>>=
library(Rdonlp2)
x0 <- c(2,-1,0)
donlp2(x0,fn1,par.lower = c(-1,-2,-Inf),par.upper =c(7,2,Inf),
       nlin=list(eqn1),nlin.l=0,nlin.u=0)$par
@
输出结果太多，篇幅所限，这里仅保留最优解！
alabama和Rdonlp2 计算结果差不多，初值可以远离局部最优点，但都能找到离初值点最近的局部最优点。

\subsection{Rsolnp包}

<<Rsolnp,eval=TRUE>>=
library(Rsolnp)
hin <- function(x){
  x1<-x[1]
  x2<-x[2]
  return(c(x1,x2))
}
x0 <-  c(3, -1,-0.02)
solnp(x0, fun = fn1, eqfun = eqn1, eqB = 0,ineqfun = hin,ineqLB = c(-1,-2),
      ineqUB = c(7,2), control = list(trace=FALSE))$pars
@
对初值要求高，一定要接近方程的解，才能收敛到局部最优解。读者可以尝试其他的初值点，体会一下效果！

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
<<include=FALSE>>=
rm(list = ls())
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{非线性规划}

优化理论的基础最近几十年来没有大的飞跃，能解的问题始终有限，但是作为一个强有力的工具，在各个学科中扮演着重要的角色。
数学优化和数学规划、非线性优化和非线性规划、凸优化和凸规划等等一对又一对的名词，本质上没有区别，优化偏数学一点，规划应是运筹学的概念。初学这个领域，发现同一本书里重复出现这些名词，常常被它们绕来绕去！书要是偏理论的一般都是用优化，偏应用都是用规划。 由于这个领域还不成熟，会发现书的框架，一会儿是按算法来分的，一会儿是按问题来分的。实际中常常出现一个算法可以解多个问题，一个问题能被多个算法解。基于应用的角度，开源实现的原则，以问题划分章节，这与文献\cite{Cortez2014Modern} 和\cite{Nash2014Nonlinear}中处理方式不同

\subsection{非线性最小二乘与无约束优化}

设因变量$Y$的期望$E(Y)$与$m$个自变量$X_1,X_2,...X_m$满足非线性的函数关系：
$$Y=\phi(X_1,X_2,...,X_m,\beta_1,\beta_2,...,\beta_r)+\epsilon=\phi(X,\beta)+\epsilon$$
其中$\beta=(\beta_1,\beta_2,...,\beta_r)'$是未知参数，$\epsilon$是误差项。

通常我们采用非线性最小二乘准则估计未知参数$\beta$，即求$\hat{\beta}$，使得
$$F(\beta)=\frac{1}{2}\sum_{i=1}^{n}\epsilon_{i}^{2}=\frac{1}{2}\sum_{i=1}^{n}(y_i-\phi(x_i,\beta))^2$$
在$\beta=\hat{\beta}$达到最小值。在这个准则下求$\hat{\beta}$，就是解一个无约束最优化问题。

我们考虑来自car包\cite{R-car}的USPop数据集---从1790年到2000年每十年一次的人口普查数据(单位:百万)，
一个简单的拟合模型就是logistic生长模型
$$y=\frac{\beta_{1}}{1+\exp[-(\beta_{2}+\beta_{3} x)]}+\epsilon$$
nls函数默认使用Gauss-Newton法计算待估系数。
非线性回归(并与线性回归比较)结果如图所示:
\begin{figure}[htb]
  \centering
    \includegraphics[width=.6\textwidth]{figure/nls.pdf}
  \caption{非线性回归}
\end{figure} 
<<tidy=FALSE>>=
data(USPop,package = "car")
plot(USPop,pch=16)
##  Gauss-Newton 
nls_model <- nls(population ~ beta1/(1+exp(-(beta2+beta3*year))),
                 start = list(beta1=400,beta2=-49,beta3=0.025),
                 data = USPop,trace = TRUE)
# summary(nls_model)
fit_model <- fitted(nls_model)
lines(fit_model~USPop$year,col="red",lwd=2)
## linear regression least-squares 
lm_model <-lm(population~year,data = USPop)
fit_lm_model <- fitted(lm_model)
lines(fit_lm_model~USPop$year,col="blue",lwd=2)
legend( "topleft",legend = c("nls","lm"),
        col = c("red","blue"),lwd = 2,cex = 1)
@


\subsection{复杂非线性回归}

这是一道面试题\footnote{\url{https://github.com/Cloud2016/Interview}}，给出了问题背景和拟合模型结构，以及求解模型所需的数据。拟合模型结构如下：
$$y=A^{(x+B)^C}+D\exp(-E(\ln x -\ln F)^2)+GH^x$$
$x$代表年龄age(已知项)，$y$是响应变量(已知项)，$A,B,...,G$是模型8个待估参数。

查看数据和散点图如下：
<<echo=FALSE,eval=TRUE,out.width='.6\\linewidth',out.height='.5\\linewidth',fig.align='center'>>=
# 导入数据
dat<-read.table(paste0(getwd(),"/data/MORTALITY.txt"),header = T,fill = T)
str(dat)
# 绘制散点图
plot(c(0,92),c(0,0.4),type = "n",xlab = "age",yaxt="n",xaxt="n",ylab ="y",pch=16)
points(dat$age,dat$y,pch=16)
x.ticks = seq(from = 0, to = 90, by = 10)
y.ticks = seq(from=0,to=0.4,by=0.05)
axis(1, at = x.ticks,  labels=x.ticks)
axis(2, at = y.ticks,  labels=y.ticks)
@


\subsection{一维优化问题}

解下列优化问题

$$\min \quad \frac{ 25R(T)+30[1-R(T)] }{(T+0.7)R(T)+ \int_{0}^{T} (t+0.9)f(t)dt }  $$
$$s.t. \quad \frac{\int_{0}^{T}R(T)dt }{(T+0.7)R(T)+ \int_{0}^{T} (t+0.9)f(t)dt} \geq 0.92 , T \geq 0$$
其中:
$$R(t)=\exp [-(\frac{t}{5000})^{2.5}]$$
$$f(t)=\frac{2.5}{5000}(\frac{t}{5000})^{1.5} \exp [-(\frac{t}{5000})^{2.5}]$$

这里$T$为未知数，即求解满足约束条件，同时使目标函数最终取值最小的时间$T$。

先写几个函数
<<eval=TRUE>>=
Rt<-function(t){  # R(t) 
  exp(-(t/5000)^(2.5))
}

Ft <- function(t){ # F(t)
  2.5/5000*(t/5000)^(1.5)*Rt(t)
}
Ftt <- function(t){ 
  (t+0.9)*Ft(t)
}

RFt <- function(t){ 
  (t+0.7)*Rt(t) + integrate(Ftt,0,t)$value
}
@
求解可行域
<<eval=TRUE>>=
f <-function(t){  # s.t. 
  integrate(Rt,0,t)$value/RFt(t) -0.92
}
uniroot(f,c(0,100)) # call the Brent Algrithm
@
目标函数
<<eval=TRUE>>=
objfun <-function(t){
 (25*Rt(t) +30*(1-Rt(t))) / RFt(t)   
}
@
调stats包内nlminb函数求解优化问题
<<eval=TRUE>>=
nlminb(9,objfun,lower = 8.05,upper = Inf)
@

小结：

通常教科书里的例子都是可以直接调用nlminb函数，一行代码了事。 
没有考虑目标函数和约束条件的复杂性，更没有考虑可行域(通常都是直接给出)。事实上，
目标函数的性质，可行域的形状都决定着优化问题的类型，求解算法的选用\footnote{此处只是想强调求解优化问题的实际过程}。


\subsection{箱式约束}
解非线性优化问题
\begin{equation*}
\begin{array}{l}
 \min \ z=(1-x)^2+100(y-x^2)^2 \\
 s.t.\left\{ \begin{array}{l}
    x \leqslant 1.9 \\
    y \leqslant 1.5
 \end{array} \right.
 \end{array}
\end{equation*}

<<eval=TRUE>>=
fr <- function(x) {
  100 * (x[2] - x[1]^2)^2 + (1 - x[1])^2
}
library(numDeriv)
grr <- function(x) {
  grad(fr,c(x[1],x[2])) # gradient
}
@

\subsubsection{optim函数}

<<eval=TRUE>>=
optim(c(-1.2, 1), fr, grr, method = "L-BFGS-B",lower = c(-Inf,-Inf),upper = c(1.9,1.5))
@

\subsubsection{nlminb函数}

<<eval=TRUE>>=
nlminb(c(-1.2,1), fr,grr,lower = c(-Inf,-Inf),upper = c(1.9,1.5))
@

\subsubsection{BB包}

BB包里的BBoptim函数可解带箱式约束(box constrains)的非线性优化问题。

<<eval=TRUE>>=
Rosenbrock <- function(x){
# Extended Rosenbrock function
  n <- length(x)
  j <- 2 * (1:(n/2))
  jm1 <- j - 1
  sum(100 * (x[j] - x[jm1]^2)^2 + (1 - x[jm1])^2)
}
p0 <- c(1.2,1.3)
BBoptim(par=p0, fn=Rosenbrock, method=3,lower = rep(0,2),upper = rep(2,2),control = list(trace=FALSE))
@

\subsubsection{Rcgmin包}
Rcgmin包\cite{R-Rcgmin}共轭梯度算法，非线性函数极小
<<eval=TRUE>>=
library(Rcgmin)
Rcgmin(fn=fr,gr=grr, par=p0,lower = rep(0,2),upper = rep(2,2))
@

\subsubsection{Rvmmin包}
Rvmmin包\cite{R-Rvmmin}变尺度算法(Variable Metric)，非线性函数极小

<<eval=TRUE>>=
library(optextras)
library(Rvmmin)
solution<-Rvmmin(fn=fr,gr=grr, par=c(1.2,1.2),lower = rep(0,2),upper = rep(2,2))
print(solution)
@

\subsubsection{dfoptim包}

dfoptim包\cite{R-dfoptim}不需要梯度信息，适用不可微的目标函数优化。
hjk函数实现Hooke-Jeeves算法，nmk函数实现Nelder-Mead算法

<<eval=TRUE>>=
library(dfoptim)
hjkb(par=p0,fn=fr, lower = rep(0,2),upper = rep(2,2))
nmkb(par=p0,fn=fr, lower = rep(0,2),upper = rep(2,2))
@

\subsection{线性约束}

\begin{equation*}
\begin{array}{l}
 \min \ z=(1-x)^2+100(y-x^2)^2 \\
 s.t.\left\{ \begin{array}{l}
    x \leqslant 1.9 \\
    y \leqslant 1.5 \\
   x-y \leqslant -0.1
 \end{array} \right.
 \end{array}
\end{equation*}

\subsubsection{constrOptim函数}

<<eval=TRUE>>=
# ui %*% theta - ci >= 0
constrOptim(c(0.5,1), fr, grr,ui = rbind(c(-1,0), c(0,-1),c(-1,1)),ci = c(-1.9,-1.5,0.1))
@

\subsection{非线性约束}

\subsubsection{NlcOptim包}

NlcOptim包\cite{R-NlcOptim}NlcOptim函数实现了序列二次规划SQP算法，适用于求解非线性目标函数，线性、非线性的等式和不等式约束优化。
一般约束优化问题，描述如下：
\begin{equation*}
\begin{array}{l}
 \min \ f(x) \\
 s.t.\left\{ \begin{array}{l}
    ceq(x) = 0  ,\quad \text{等式约束}  \\
    c(x) \leqslant 0 ,\quad \text{不等式约束}\\
    Ax \leqslant B   ,\quad \text{线性不约束} \\
    Aeqx \leqslant Beq ,\quad \text{线性等式约束} \\
    lb \leqslant x \leqslant ub ,\quad \text{变量边界约束} 
 \end{array} \right.
 \end{array}
\end{equation*}

以下列非线性优化问题为例：
\begin{equation*}
\begin{array}{l}
 \min \ z=(1-x)^2+100(y-x^2)^2 \\
 s.t.\left\{ \begin{array}{l}
    x^2+y^2 \leqslant 2 \\
    y-x = 0 \\
    0 \leqslant x \leqslant 2 \\
    0 \leqslant y \leqslant 2 
 \end{array} \right.
 \end{array}
\end{equation*}

<<eval=TRUE>>=
library(MASS)
library(NlcOptim)
# 约束条件函数
con <- function(x){
  f=NULL # 不等式约束
  f=rbind(f,x[1]^2+x[2]^2-2)
  g=NULL  # 等式约束
  g=rbind(g,x[2]-x[1])
  return(list(ceq=g,c=f))
}
# lb,ub 矩阵类型
NlcOptim(X=c(0,0),objfun=fr,confun=con,lb = as.matrix(rep(0,2)),ub = as.matrix(rep(2,2)))
@
再举个例子
\begin{equation*}
\begin{array}{l}
 \max \ z= \frac{\sin(2\pi x)^3 \sin(2\pi y)}{x^3 (x+y)}   \\
 s.t.\left\{ \begin{array}{l}
    x^2-y+1 \leqslant 0 \\
    1-x + (y-4)^2 \leqslant 0 \\
    0 \leqslant x,y \leqslant 10
 \end{array} \right.
 \end{array}
\end{equation*}
对于这种复杂的例子，初始猜测值需要接近最优解才会有好的效果！
<<eval=TRUE>>=
fr <- function(x){
  # NlcOptim函数默认求极小，因此目标函数添加负号
  -sin(2*pi*x[1])^3*sin(2*pi*x[2])/(x[1]^3*(x[1]+x[2]))  
}
con <- function(x){
  f=NULL # 不等式约束
  f=rbind(f,x[1]^2-x[2]+1)
  f=rbind(f,1-x[1]+(x[2]-4)^2)
  return(list(ceq=NULL,c=f))
}
NlcOptim(X=c(1.2,4.2),objfun=fr,confun=con,lb = as.matrix(rep(0,2)),ub = as.matrix(rep(10,2)))
@

Rdonlp2包也需要一个好的初始值，才能获得最优解。
<<eval=TRUE>>=
# library(Rdonlp2)
x0 <- c(1,4)
con1 <- function(x){
  x[1]^2-x[2]+1
}
con2 <- function(x){
  1-x[1]+(x[2]-4)^2
}
nlin.l = c(-Inf,-Inf)
nlin.u = c(0,0)
donlp2(par = c(1.2,4.1), fr, par.lower = c(0, 0), par.upper = c(10,10), 
       nlin = list(con1,con2),nlin.l = nlin.l, nlin.u = nlin.u)$par
@

\subsubsection{Rnlminb2包}

Rnlminb2包\cite{R-Rnlminb2}内点法求解非线性约束优化，是nlminb的升级版，因为添加了非线性约束。

<<eval=TRUE>>=
library(Rnlminb2)
nlminb2NLP(start = c(1.2,4.1),fun = fr,eqFun = list(con1,con2),par.lower = c(0,0),par.upper = c(10,10))
@

以上出现的求解非线性规划的R包和函数都只能获得局部最优解！

\subsection{凸优化}

一般非线性优化问题：
$$\min \quad f(x) $$
$$s.t. \quad g(x)  = 0 $$
$$l_{h} \leq  h(x) \leq u_{h}  $$
$$l_{x} \leq  x  \leq u_{x} $$
其中$f(x)$，$g(x)$和$h(x)$是光滑的

求解下列优化问题
$$\min \quad f(x) = -2x_{1}^{2}-x_{2}^{2}$$
$$s.t. \quad x_{1}^{2}+x_{2}^{2}-2  = 0 $$
$$ x_{2}-e^{x_{1}} \geq 0  $$
$$ x_{1},x_{2} \geq 0 $$
 
可行域是一段弧，这里加载Rsolnp包，调用solnp函数求解，基于增广拉格朗日乘子法和SQP内点算法
<<eval=TRUE>>=
library(Rsolnp)
fn1 <- function(x){
  -2*x[1]^2-x[2]^2
}
eqn1 <-function(x){
   x[1]^2+x[2]^2
}
ineqn1 <-function(x){
 exp(x[1])-x[2]
}
x0 =c(1/2,sqrt(3)/2)
solnp(x0, fun = fn1, eqfun = eqn1, eqB = 2,
      ineqfun = ineqn1,ineqLB = -Inf,ineqUB = 0,
      LB=c(0,0),UB=c(Inf,Inf) )
@

$$\min \quad f(x) = -2x_{1}^{2}-x_{2}^{2}$$
$$s.t. \quad x_{1}^{2}+x_{2}^{2}-2 \leq 0 $$
$$ -x_{1} +x_{2} \geq 0  $$
$$ x_{1},x_{2} \geq 0 $$

<<eval=TRUE>>=
ineqn2 <-function(x){
  c(x[1]^2+x[2]^2,x[1]-x[2]) 
}
solnp(c(1/2,3/4), fun = fn1, eqfun = eqn1, eqB = 2,
      ineqfun = ineqn2,ineqLB = c(-Inf,-Inf),ineqUB = c(2,0),
      LB=c(0,0),UB=c(Inf,Inf) )
@



\subsection{应用}
\subsubsection{正态分布参数估计}
估计正态分布的参数
<<eval=TRUE,tidy=FALSE>>=
set.seed(123)
n <- 1000  # 产生n个正态随机数
mu <- 4   # 预先设定的均值和方差
Var <- 4
x <- rnorm(n,mean=mu,sd= Var)
# 矩估计
theta <- c(mu=mean(x),sigma=sqrt((n-1)*var(x)/n))  
# 存储数据
# library(RevoScaleR)
# rxDataStep(inData = data.frame(x), outFile = "optim-work.xdf", 
# 		    	 overwrite = TRUE,rowsPerRead = 2000, reportProgress = 0)
# 对数似然函数
logLikFun <- function(param, mleData) {
  # param 待估参数
		 mu <- param[1]  # 均值
		 sigma <- param[2] # 方差
		 -sum(dnorm(mleData, mean = mu, sd = sigma, log = TRUE))
}
# 二元无约束优化 optim默认选择方法：Nelder and Mead
mle <- optim(par = c(mu = 0, sigma = 1),fn = logLikFun,mleData = x)
# 样本量很大的时候，最大似然估计没有矩估计好
rbind(mle = mle$par, standard = theta)
@
<<include=FALSE>>=
rm(list = ls())
@
改变样本量计算均值和方差，比较两种估计随样本量的变化！\\
样本量小(1000)的时候，均值，似然估计比矩估计差，方差，似然估计比矩估计好 \\
样本量大(10000)的时候，矩估计均值方差一致比似然估计好

\subsubsection{二项泊松混合分布参数估计}

Nelder-Mead数值方法
<<eval=TRUE,tidy=FALSE>>=
set.seed(1234)   # 设置随机数种子,用于可重复实现
# 产生二项泊松混合分布随机数
bipossion <- function(n,p,theta){
	# n 随机数个数
	# p 比列 向量 sum(p)=1 
	# theta 泊松分布参数 length(theta) 子泊松分布个数
	# length(p)=length(theta)=2
	x <- rep(NA,n)
	temp <- rbinom(n,1,p)  
#	x <- ifelse(temp==1,rpois(1,theta[1]),rpois(1,theta[2]))  # 为何不对
	for(i in seq(n)){
	   if(temp[i]==1) x[i] <- rpois(1,theta[1])
	   if(temp[i]==0) x[i] <- rpois(1,theta[2])
	}	
	return(x)
}

# 似然函数
fun <- function(mleData){
  logLikFun <- function(param){
    p <- param[1];
    theta1 <- param[2];
    theta2 <- param[3];	
    -sum(log(p*dpois(mleData,theta1)+(1-p)*dpois(mleData,theta2)))
  }
  return(logLikFun)
}
# 矩估计和最大似然估计
ME_MLE <- function(n,p,theta){
  x <- bipossion(n,p,theta) ## 二项泊松混合分布
  x1 <- rpois(n,theta[1])
  x2 <- rpois(n,theta[2])
  ME <- c(mean(x1),mean(x2)) # ME矩估计 moment estimation
  MLE <- optim(par = c(0.06,mean(x1),mean(x2)),fn = fun(mleData=x))$par  
  # MLE估计  maximum likelihood estimation
  list(me=ME,mle=MLE)
}
system.time(res<- ME_MLE(n=10000,p=0.6,theta = c(2,4)))
res
@

SANN模拟退火方法
<<eval=TRUE>>=
n=10000
p=0.6
theta=c(2,4)
x <- bipossion(n,p,theta) 
x1 <- rpois(n,theta[1])
x2 <- rpois(n,theta[2])
optim(par = c(0.06,mean(x1),mean(x2)),fn = fun(mleData=x),method="SANN")

@

牛顿-拉弗森算法
<<eval=TRUE>>=
library(Deriv)
expr <- expression(p*theta1^x/exp(theta1)+(1-p)*theta2^x/exp(theta2)) 
DFun <- sapply(all.vars(expr)[-3], function(v) {
	Simplify(D(expr, v)) # 表达式求偏导
})
tempFun <- function(x){
	equations <- function(m) {
		p = m[1]
		theta1 = m[2]
		theta2 = m[3]
		f1 <- sum( (dpois(x,theta1)-dpois(x,theta2)) /(p*dpois(x,theta1)+(1-p)*dpois(x,theta2) ))
		f2 <- sum( (p*eval(DFun$theta1)/factorial(x)) /(p*dpois(x,theta1)+(1-p)*dpois(x,theta2)) )
		f3 <- sum( ((1-p)*eval(DFun$theta2)/factorial(x)) /(p*dpois(x,theta1)+(1-p)*dpois(x,theta2)) )
		c(f1, f2, f3)
	}
	return(equations)
}
multiroot(f = tempFun(x), start = c(0.06, mean(x1), mean(x2)))$root
@
BB算法
<<eval=TRUE>>=
# 比rootSolve效果好 ,能收敛到真解, 只是误差较大 
BBsolve(par = c(0.06, mean(x1), mean(x2)), fn = tempFun(x),method=2, 
	    	control = list(trace = FALSE,NM=TRUE, tol = 1e-15))$par
@
调multiStart函数
<<>>=
p0 <- matrix(runif(900), 300, 3) # 300组初始值
ans <- multiStart(par = p0, fn = tempFun(x), action = "solve")
sum(ans$conv)  # 收敛的情况数目
pmat <- ans$par[ans$conv, ]
ord1 <- order(pmat[, 1])
ans <- round(pmat[ord1, ], 4)
ans[!duplicated(ans), ]
@

nls非线性回归
<<eval=TRUE>>=
Poisson <- data.frame(x=seq(from=0,to=13,by=1),
	y=c(0.0862 ,0.1862, 0.2257, 0.1831 ,
	0.1375, 0.0853 ,0.0508, 0.0244 ,
	0.0124 ,0.0046, 0.0024, 0.0008 ,
	0.0004, 0.0002)) 
nls(y ~ p*dpois(x,theta1)+(1-p)*dpois(x,theta2),
         start = list(p=0.06,theta1= mean(x1),theta2=mean(x2)),
         data = Poisson,trace = FALSE)
@

nlm无约束极小
<<eval=TRUE>>=
fun <- function(mleData){
  logLikFun <- function(param){
    p <- param[1];
    theta1 <- param[2];
    theta2 <- param[3];	
    -sum(log(p*dpois(mleData,theta1)+(1-p)*dpois(mleData,theta2)))
  }
  return(logLikFun)
}
nlm(fun(x), c(0.06,mean(x1),mean(x2)), hessian = FALSE)
@

Rdonlp2大规模无约束极小
<<eval=TRUE>>=
donlp2(c(0.06,mean(x1),mean(x2)),fun(x))$par
@

BFGS算法
<<eval=TRUE>>=
grr <- function(param) {
	grad(fun(x),c(param[1],param[2],param[3])) # gradient
}
optim(c(0.06,mean(x1),mean(x2)), fun(x), grr, method = "BFGS")$par
@

BBoptim

<<eval=TRUE>>=
# Log-likelihood for a binary Poisson mixture distribution
poissmix.loglik <- function(p,y) {
# p 参数：比例 theta1 theta2  y 频率数据
	i <- 0:(length(y)-1)
	loglik <- y * log(p[1] * exp(-p[2]) * p[2]^i / exp(lgamma(i+1)) +
			  (1 - p[1]) * exp(-p[3]) * p[3]^i / exp(lgamma(i+1)))	
	return (sum(loglik) )
}
lo <- c(0,0,0) # lower limits for parameters
hi <- c(1, Inf, Inf) # upper limits for parameters
p0 <- c(0.06,mean(x1),mean(x2)) # a randomly generated vector of length 3
y  <- c( 862, 1862, 2257, 1831, 1375,  853 , 508 , 244 , 124,   46  , 24  ,  8 ,   4 ,   2 )
BBoptim(par=p0, fn=poissmix.loglik, y=y,
				lower=lo, upper=hi, control=list(maximize=TRUE))$par
@

GenSA
<<eval=TRUE,tidy=FALSE>>=
library(GenSA)
poissmix.loglik <- function(p,y) {
	i <- 0:(length(y)-1)
	loglik <- y * log(p[1] * exp(-p[2]) * p[2]^i / exp(lgamma(i+1)) +
			  (1 - p[1]) * exp(-p[3]) * p[3]^i / exp(lgamma(i+1)))	
	return (-sum(loglik) )
}
lower <- c(0,0,0)
upper <- c(1,Inf,Inf)
tol	<- 1e-13
ctrl <- list(threshold.stop=tol,verbose =TRUE)
SA1 <- GenSA(par=c(0.06,mean(x1),mean(x2)),lower = lower,upper = upper,
				y=y,fn=poissmix.loglik,control = ctrl)
print(SA1[c("value","par","counts")])
@

DEoptim差分进化
<<eval=TRUE>>=
library(DEoptim)
loglik <- function(y) {
# p 参数：比例 theta1 theta2  y 频率数据
fun<- function(p){
			i <- 0:(length(y)-1)
			loglik <- y * log(p[1] * exp(-p[2]) * p[2]^i / exp(lgamma(i+1)) +
					(1 - p[1]) * exp(-p[3]) * p[3]^i / exp(lgamma(i+1)))	
			return (-sum(loglik) )
   }
	return(fun)
}
lower <- c(0,0,0)
upper <- c(1,10,10)
DEopt <- DEoptim(lower = lower,upper = upper,
					fn=loglik(y),control = list(trace=FALSE))
print(DEopt$optim)
@

A simple Monte Carlo optimizer using adaptive coordinate sampling
<<eval=TRUE,message=FALSE>>=
library(smco)
asmcol<- smco(par=c(0.06,mean(x1),mean(x2)),LB=lower,UB=upper,
				fn=loglik(y),maxiter = 100000,trc = FALSE)
print(asmcol[c("par","value")])
@



\subsection{Scilab接口}

Scilab\footnote{http://www.scilab.org/}功能类似MATLAB，同样的开源软件还有Octave\footnote{http://www.gnu.org/software/octave/}。optimbase包\cite{R-optimbase}、optimsimplex包\cite{R-optimsimplex}、neldermead包\cite{R-neldermead}和Matrix包\cite{R-Matrix}，合一起实现开源软件Scilab内的基本命令和优化求解器fminsearch。

<<eval=TRUE>>=
library(Matrix)
library(optimbase)
library(optimsimplex)
library(neldermead)
zeros(3)
ones(4,5)
@


<<>>=
#function evaluations
banana <- function(x){
  y <- 100*(x[2]-x[1]^2)^2 + (1-x[1])^2
}
sol <- fminsearch(banana, c(-1.2,1))
sol

opt <- optimset(TolX=1.e-2)
# The absolute tolerance on simplex size. The default value is 1.e-4.
sol <- fminsearch(banana, c(-1.2,1), opt)
sol
  
outfun <- function(x, optimValues, state){
    plot(x[1],x[2],xlim=c(-1.5,1.5),ylim=c(-1.5,1.5))
    par(new=TRUE)
  }
opt <- optimset(OutputFcn=outfun)
sol <- fminsearch(banana, c(-1.2,1), opt)
sol

opt <- optimset(MaxIter=10)
sol <- fminsearch(banana, c(-1.2,1), opt)

opt <- optimset(Display='iter')
sol <- fminsearch(banana, c(-1.2,1), opt)
sol
@

\section{启发式算法}

\subsection{随机数生成}

随机数发生器\footnote{确切地说是伪随机数发生器Pseudo-Random Number Generator} (Random Number Generator) 是进行随机模拟的基础，
如果没有可靠的随机数发生器，一切计算结果都没有说服力。
一个好的随机数发生器，必是在效率和质量之间取得很好的平衡！
效率就是短时间内产生足够多的随机数，质量就是通过一系列测试，以满足计算需要。

如果有一天模拟的结果不是预想的那样，程序也没有出错(事实上，十有八九就是程序出问题)，
就该考虑随机数发生器了。

如果不是涉及到超大规模的模拟计算，一般计算软件内置的随机数发生器就能满足计算需要了。

下面以R软件平台为例，就Mersenne-Twister随机数发生器做Run-Length测试，

\begin{figure}[htb]
  \centering
    \includegraphics[width=.8\textwidth]{figure/RunLengthTest}
  \caption{游程检验}
\end{figure} 

<<echo=TRUE,eval=FALSE>>=
set.seed(1234,kind="Mersenne-Twister")
n=2^24
x<-runif(n)
delta=0.01
len<- diff(c(0,which(x<delta),n+1))-1
dat <- table(len[len < 100])
ylabs<-seq(0,1800,by=200)
xlabs<-seq(0,100,by=10)
	
hist(len[len < 100],breaks=-1:99,
	col="#352A86",border="black",
	axes = FALSE,ann=FALSE)
title(main="Mersenne-Twister")	
axis(1,labels=xlabs,at=xlabs,las=1)  # x-axis
axis(2,labels=ylabs,at=ylabs,las=1)  # y-axis
box()
@


\newpage
\section{R软件信息}
<<eval=TRUE>>=
sessionInfo()
devtools::session_info()
@
% 本文是在RStudio环境下用R sweave编写的，用knitr\cite{R-knitr}处理R代码，\XeLaTeX{}编译生成pdf文档。

\renewcommand\refname{参考文献} 
\bibliographystyle{unsrt}
\bibliography{Optimization.bib} 




\end{document}